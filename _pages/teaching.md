---
layout: page
permalink: /teaching/
title: Teaching
description: "I am currently teaching the following courses for undergraduate students majoring in Artificial Intelligence at Beijing University of Technology: Natural Language Processing (Course No. 0000635) and Comprehensive Practice of Natural Language Processing (Course No. 0010748)."
nav: true
nav_order: 6
---

## ðŸ”¹ Natural Language Processing

**Course No.** 0000635 | **Undergraduate**

This course serves as the foundational pillar for the AI major, systematically covering the core theories and techniques of Natural Language Processing. The curriculum begins with essential building blocks such as Word Vectors, Dependency Parsing, and Language Modeling, establishing a rigorous theoretical framework. It then progresses to deep learning architectures, covering Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs), which lay the groundwork for understanding sequence modeling. Reflecting the rapid advancements in AI, a significant portion of the course is dedicated to state-of-the-art (SOTA) technologies. Students will dive deep into Attention Mechanisms, the revolutionary Transformer architecture, and Pre-training paradigms. The course culminates in the exploration of frontier topics that power modern Large Language Models (LLMs) like ChatGPT, including Natural Language Generation, Prompting, and Reinforcement Learning from Human Feedback (RLHF). By integrating these advanced topics, the course ensures that students are well-prepared to engage in top-tier AI research and solve complex real-world problems.

## ðŸ”¹ Comprehensive Practice of NLP

**Course No.** 0010748 | **Undergraduate**

Designed as the vital practical companion to the theoretical Natural Language Processing course, this module bridges the gap between abstract concepts and real-world application. Students are strongly encouraged to take these two courses simultaneously to achieve a synergistic understanding of both theory and practice. The curriculum features hands-on experiments hosted on online evaluation platforms (e.g., Kaggle), ensuring that practical tasks are rigorously synchronized with the theoretical syllabusâ€”from implementing basic models to deploying advanced algorithms like Transformers. Beyond standard experiments, the course culminates in an open-ended capstone project where students work in teams to design and build their own custom NLP systems from scratch. This approach not only fosters engineering skills and teamwork but also encourages students to innovate and tackle authentic challenges through the complete pipeline of problem analysis, system architecture, and performance evaluation.
